{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import scipy.sparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best = 20\n",
    "\n",
    "def get_line_from_file_by_id(filename, id):\n",
    "    with open(filename) as inf:\n",
    "        for i, line in enumerate(inf):\n",
    "            if i == id:\n",
    "                return line\n",
    "            \n",
    "def get_line_from_filelist_by_id(filelist, id):\n",
    "    return filelist[id]\n",
    "\n",
    "with open('data/train.diff', 'r') as inf:\n",
    "    train_diff_list = []\n",
    "    for line in inf:\n",
    "        train_diff_list.append(line)\n",
    "\n",
    "with open('data/train.msg', 'r') as inf:\n",
    "    train_msg_list = []\n",
    "    for line in inf:\n",
    "        train_msg_list.append(line)\n",
    "            \n",
    "#def extract_train_diff(id):\n",
    "#    return get_line_from_file_by_id('data/train.diff', id)\n",
    "\n",
    "def extract_train_diff(id):\n",
    "    return get_line_from_filelist_by_id(train_diff_list, id)\n",
    "            \n",
    "#def extract_target_commit_message(id):\n",
    "#    return get_line_from_file_by_id('data/train.msg', id)\n",
    "\n",
    "def extract_target_commit_message(id):\n",
    "    return get_line_from_filelist_by_id(train_msg_list, id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_diffs = []\n",
    "with open('data/test.diff', 'r') as inf:\n",
    "    for line in inf:\n",
    "        new_diffs.append(line.strip())\n",
    "#new_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 179 ms, sys: 56.5 ms, total: 235 ms\n",
      "Wall time: 240 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#load vocabulary\n",
    "with open('data/vocabulary.json', 'r') as inf:\n",
    "    vocabulary = json.load(inf) \n",
    "vectorizer = CountVectorizer(vocabulary=vocabulary, token_pattern=r'\\S+', stop_words=['<nl>'])\n",
    "\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "#load bag-of-words matrix\n",
    "train_bow_matrix = scipy.sparse.load_npz('data/bow_matrix.npz')\n",
    "#train_bow_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.53 s, sys: 19.7 ms, total: 1.55 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "newdiff_bow_matrix = vectorizer.transform(new_diffs)\n",
    "#newdiff_bow_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 s, sys: 9.82 s, total: 38 s\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cosine_matrix = cosine_distances(newdiff_bow_matrix, train_bow_matrix)\n",
    "#cosine_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 s, sys: 25 ms, total: 22.3 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "candidates_indices = [(row.argsort()[:k_best]).tolist() for row in cosine_matrix]\n",
    "#len(candidates_indices[0]), len(candidates_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5581, 45897)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best(diff, ids):\n",
    "    best_bleu = 0.0\n",
    "    best_id = ids[0]\n",
    "    for id in ids:\n",
    "        reference = extract_train_diff(id)\n",
    "        score = sentence_bleu([analyzer(reference)], analyzer(diff))\n",
    "        if score > best_bleu:\n",
    "            best_bleu = score\n",
    "            best_id = id\n",
    "    return best_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ne0n/miniconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ne0n/miniconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ne0n/miniconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "CPU times: user 5min 3s, sys: 612 ms, total: 5min 4s\n",
      "Wall time: 5min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "messages_id = []\n",
    "for i, diff in enumerate(new_diffs):\n",
    "    cur_id = choose_best(diff, candidates_indices[i])\n",
    "    messages_id.append(cur_id)\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "#print(new_diffs, extract_train_diff(0), extract_train_diff(1), extract_train_diff(2), extract_train_diff(3))\n",
    "    \n",
    "#len(messages_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/generated.msg', 'w') as ouf:\n",
    "    for i, message_id in enumerate(messages_id):\n",
    "        message = extract_target_commit_message(message_id)\n",
    "        ouf.write(message)\n",
    "        #if i % 100 == 0:\n",
    "        #    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
