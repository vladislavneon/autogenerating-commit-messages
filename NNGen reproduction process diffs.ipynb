{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import scipy.sparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best = 5\n",
    "\n",
    "def get_line_from_file_by_id(filename, id):\n",
    "    with open(filename) as inf:\n",
    "        for i, line in enumerate(inf):\n",
    "            if i == id:\n",
    "                return line\n",
    "            \n",
    "def extract_train_diff(id):\n",
    "    return get_line_from_file_by_id('data/train.diff', id)\n",
    "            \n",
    "def extract_target_commit_message(id):\n",
    "    return get_line_from_file_by_id('data/train.msg', id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_diffs = []\n",
    "with open('data/test.diff', 'r') as inf:\n",
    "    for line in inf:\n",
    "        new_diffs.append(line.strip())\n",
    "#new_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load vocabulary\n",
    "with open('data/vocabulary.json', 'r') as inf:\n",
    "    vocabulary = json.load(inf) \n",
    "vectorizer = CountVectorizer(vocabulary=vocabulary, token_pattern=r'\\S+', stop_words=['<nl>'])\n",
    "\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "#load bag-of-words matrix\n",
    "train_bow_matrix = scipy.sparse.load_npz('data/bow_matrix.npz')\n",
    "#train_bow_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 59678)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdiff_bow_matrix = vectorizer.transform(new_diffs)\n",
    "newdiff_bow_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 26208)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_matrix = cosine_distances(newdiff_bow_matrix, train_bow_matrix)\n",
    "cosine_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3000)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_indices = [(row.argsort()[:k_best]).tolist() for row in cosine_matrix]\n",
    "len(candidates_indices[0]), len(candidates_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ne0n/miniconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ne0n/miniconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_best(diff, ids):\n",
    "    best_bleu = 0.0\n",
    "    best_id = ids[0]\n",
    "    for id in ids:\n",
    "        reference = extract_train_diff(id)\n",
    "        score = sentence_bleu([analyzer(reference)], analyzer(diff))\n",
    "        if score > best_bleu:\n",
    "            best_bleu = score\n",
    "            best_id = id\n",
    "    return best_id\n",
    "\n",
    "messages_id = []\n",
    "for i, diff in enumerate(new_diffs):\n",
    "    cur_id = choose_best(diff, candidates_indices[i])\n",
    "    messages_id.append(cur_id)\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "#print(new_diffs, extract_train_diff(0), extract_train_diff(1), extract_train_diff(2), extract_train_diff(3))\n",
    "    \n",
    "len(messages_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n"
     ]
    }
   ],
   "source": [
    "with open('data/generated.msg', 'w') as ouf:\n",
    "    for i, message_id in enumerate(messages_id):\n",
    "        message = extract_target_commit_message(message_id)\n",
    "        ouf.write(message)\n",
    "        if i % 100 == 0:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['updated', 'changelog', 'for', '2', '.', '1', '.', '0', '-', 'snapshot', '.']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer('updated CHANGELOG for 2 . 1 . 0 - SNAPSHOT .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
